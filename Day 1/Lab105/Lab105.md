**<u>Lab 105</u>** (**<u>Run and interpret evaluation</u>**)

In the previous lab, we configured OpenScale. In this lab, we will configure various model evaluation monitors, and then run an evaluation to calculate these metrics.

1.  **<u>Configure fairness monitors</u>**

    1.  From the list of Evaluations on the left, click on fairness.

    2.  Note the description of fairness in the centre of the screen, which gives a good definition of what the monitor is evaluating. Click on the edit icon in the configuration tile.

<img src="./images/media/image1.png" style="width:6.26806in;height:1.97222in" alt="A screenshot of a computer Description automatically generated" />

    3.  You will manually configure the fairness files. Leave configure manually selected and click Next to proceed. To properly monitor a model for unfair bias, you must specify which model outcomes are favourable and which are unfavourable. For our use, favourable class is No Risk and non-favourable class is Risk. Click Next.

    <img src="./images/media/image2.png" style="width:6.26806in;height:2.88681in" alt="A screenshot of a computer Description automatically generated" />

    4.  Set the minimum sample size to 50 and click next.

    > <img src="./images/media/image3.png" style="width:6.26806in;height:2.48194in" alt="A screenshot of a computer Description automatically generated" />

    5.  Leave the selected monitored metrics set to Disparate impact and click Next.

    <img src="./images/media/image4.png" style="width:6.26806in;height:2.48264in" alt="A screenshot of a computer Description automatically generated" />

    6.  Leave the lower and upper thresholds for Disparate impact set to their defaults, and click Next.

    <img src="./images/media/image5.png" style="width:6.26806in;height:2.45208in" alt="A screenshot of a computer Description automatically generated" />

    7.  In the next screen, select the fields that you need to monitor for fairness. For now, retain the default values suggested by OpenScale (after analyzing the training data). Click Next.

    <img src="./images/media/image6.png" style="width:6.26806in;height:2.53125in" alt="A screenshot of a computer Description automatically generated" />

    8.  In the next screen, select the groups which are to be monitored against the reference group. Here, the percentage of favorable outcomes delivered to the monitored groups will be compared to the percentage of favorable outcomes delivered to the remaining groups (the reference groups) to check for potential bias.

    <img src="./images/media/image7.png" style="width:6.26806in;height:2.42361in" alt="A screenshot of a computer Description automatically generated" />

    <img src="./images/media/image8.png" style="width:6.26806in;height:2.50347in" alt="A screenshot of a computer Description automatically generated" />

    <img src="./images/media/image9.png" style="width:6.26806in;height:2.46389in" alt="A screenshot of a computer Description automatically generated" />

    <img src="./images/media/image10.png" style="width:6.26806in;height:2.71319in" alt="A screenshot of a computer Description automatically generated" />

    9.  Use the default alert threshold (80), and click Save to finish configuring the fairness monitor. It may take up to a minute for the configuration to save, at which point you will be returned to the model settings screen.

<!-- -->

2.  **<u>Configure the quality monitor</u>**

    1.  From the list of evaluations on the left, click on Quality.

    2.  Click the edit icon on the Quality thresholds tile.

> <img src="./images/media/image11.png" style="width:6.26806in;height:2.26528in" alt="A screenshot of a computer Description automatically generated" />

    3.  Click the Edit icon on the Quality thresholds tile.

    4.  Leave the default lower and upper threshold values as they are. You can click the Information icon to the right of each value for more information on how it is calculated. Click Next.

    <img src="./images/media/image12.png" style="width:6.26806in;height:2.46736in" alt="A screenshot of a computer Description automatically generated" />

    5.  Set the Minimum sample size value to 50. Click Save to save the quality configuration.

<!-- -->

3.  **<u>Configure the explainability service</u>**

    1.  In the Explainability section, click on General settings, and in the explanation method tile, click on the Edit icon.

<img src="./images/media/image13.png" style="width:6.26806in;height:2.49028in" alt="A screenshot of a computer Description automatically generated" />

    2.  Two different methods are available for explanations: Shapley Additive Explanations (SHAP) or Local Interpretable Model-agnostic Explanations (LIME). As described in hint that appears when you click the Information box, SHAP often provides more thorough explanations, but LIME is faster.

    3.  Leave the LIME method selected and click Save.

<!-- -->

4.  **<u>Run an evaluation</u>**

    1.  Return to the Insights Dashboard by clicking on the Dashboard link the upper left, and click on the tile for the model you configured (german-credit-risk-testing)

    2.  Click on the Actions button to open the Actions menu, click on Evaluate now.

<img src="./images/media/image14.png" style="width:6.26806in;height:2.52569in" alt="A screenshot of a computer Description automatically generated" />

    3.  Import test data screen pops up, select import from CSV file and then browse the test file from your local system, and keep the option of Test data includes output as unchecked.

    <img src="./images/media/image15.png" style="width:6.26806in;height:2.67292in" alt="A screenshot of a computer Description automatically generated" />

    4.  Click Upload and evaluate.

After some time, the results of the evaluation can be seen in the dashboard.

5.  **<u>Viewing and interpreting the results</u>**

    1.  Take a moment to review the results of the evaluation. Note that, based on the content of the random sample of the evaluation data, your results will vary each time you perform the evaluation.

    2.  Review the different metrics in the quality table. In the screenshot below, notice that, if the measurement falls below the alert threshold set when you configured the quality monitor, the amount will be listed in the Violation column of the table.

> <img src="./images/media/image16.png" style="width:6.26806in;height:2.60903in" alt="A screenshot of a test results Description automatically generated" />

    3.  Beyond meeting standards for quality and fairness, AI models in many cases are required to provide explanations into the decisions or predictions they make. This can be viewed in watsonx.governance by clicking on the arrow icon in the fairness tile, and then selecting view payload transactions.

    <img src="./images/media/image17.png" style="width:6.26806in;height:2.88681in" alt="A screenshot of a computer Description automatically generated" />

    <img src="./images/media/image18.png" style="width:6.26806in;height:2.44306in" alt="A screenshot of a computer Description automatically generated" />

    4.  From the table of transactions, click one of the Explain prediction links. The explainability service will use the LIME algorithm to generate a detailed explanation, which can take a few minutes to run.

    > <img src="./images/media/image19.png" style="width:6.26806in;height:2.05972in" alt="A screenshot of a group Description automatically generated" />

    5.  Once the explanation has been generated, scroll down to the graph, which shows the influence different features had in the model's outcome. Features in blue increased the final score, while those in red decreased it. For classification models, blue features contributed positively to the model's confidence in the prediction, while those in red decreased the confidence.

    > <img src="./images/media/image20.png" style="width:6.26806in;height:2.76875in" alt="A screenshot of a computer Description automatically generated" />

    6.  Click on the Inspect tab. On this tab, you can alter values associated with the record and re-submit it to the model to see how the final risk calculation changes. This can be useful for understanding how the model is working, or if a policyholder is looking for ways to decrease their risk assessment.

> <img src="./images/media/image21.png" style="width:6.26806in;height:2.475in" alt="A screenshot of a computer Description automatically generated" />
